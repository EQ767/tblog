<!DOCTYPE html>
<html lang="zh">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>离线运行AI模型的简单方法</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            margin: 20px;
            background-color: #f4f4f4;
        }
        h1, h2, h3 {
            color: #333;
        }
        h1 {
            text-align: center;
        }
        .container {
            max-width: 900px;
            margin: 0 auto;
            background-color: #fff;
            padding: 20px;
            border-radius: 8px;
            box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
        }
        nav ul {
            list-style-type: none;
            padding: 0;
        }
        nav ul li {
            margin-bottom: 10px;
        }
        nav ul li a {
            text-decoration: none;
            color: #0066cc;
        }
        nav ul li a:hover {
            text-decoration: underline;
        }
        code {
            background-color: #f1f1f1;
            padding: 4px;
            border-radius: 4px;
        }
        pre {
            background-color: #f1f1f1;
            padding: 10px;
            border-radius: 4px;
            overflow-x: auto;
        }
    </style>
</head>
<body>

    <div class="container">
        <h1>离线运行AI模型的简单方法</h1>

        <nav>
            <ul>
                <li><a href="#HuggingFace">方法1：使用 Hugging Face 加载模型</a></li>
                <li><a href="#Docker">方法2：使用 Docker 容器</a></li>
                <li><a href="#GPT4All">方法3：使用 GPT4All 桌面客户端</a></li>
            </ul>
        </nav>

        <hr>

        <section id="HuggingFace">
            <h2>方法1：使用 Hugging Face 加载模型</h2>
            <p>Hugging Face 提供了许多开源模型，你可以将这些模型下载到本地并离线运行。适合需要高度自定义的用户。</p>
            <p><strong>优化步骤：</strong></p>
            <ol>
                <li>安装依赖：<code>pip install transformers torch</code> （<a href="https://huggingface.co/docs/transformers/installation" target="_blank">Hugging Face 安装文档</a>）</li>
                <li>下载模型并保存至本地：你可以从 <a href="https://huggingface.co/models" target="_blank">Hugging Face 模型库</a> 中选择并下载模型。</li>
                <pre><code>from transformers import AutoModelForCausalLM, AutoTokenizer

model = AutoModelForCausalLM.from_pretrained("EleutherAI/gpt-neo-1.3B")
tokenizer = AutoTokenizer.from_pretrained("EleutherAI/gpt-neo-1.3B")

# 保存模型到本地
model.save_pretrained("./gpt-neo-1.3B")
tokenizer.save_pretrained("./gpt-neo-1.3B")</code></pre>
                <li>离线加载模型并生成文本：</li>
                <pre><code># 离线使用
model = AutoModelForCausalLM.from_pretrained("./gpt-neo-1.3B")
tokenizer = AutoTokenizer.from_pretrained("./gpt-neo-1.3B")

# 输入文本生成输出
inputs = tokenizer("你好，世界！", return_tensors="pt")
outputs = model.generate(**inputs)
print(tokenizer.decode(outputs[0], skip_special_tokens=True))</code></pre>
                <li>详细文档可以查看 <a href="https://huggingface.co/docs/transformers" target="_blank">Hugging Face 文档</a>。</li>
            </ol>
        </section>

        <hr>

        <section id="Docker">
            <h2>方法2：使用 Docker 容器</h2>
            <p>Docker 是一种轻量级的虚拟化工具，可以快速部署 AI 模型并在本地运行，适合有系统环境隔离需求的用户。</p>
            <p><strong>优化步骤：</strong></p>
            <ol>
                <li>安装 Docker：可以参考 <a href="https://docs.docker.com/get-docker/" target="_blank">Docker 官方安装指南</a>。</li>
                <li>拉取并运行模型镜像：</li>
                <pre><code>docker pull floydhub/dl-docker:cpu</code></pre>
                <li>启动容器并运行模型：</li>
                <pre><code>docker run -it --rm floydhub/dl-docker:cpu bash</code></pre>
                <li>在容器内安装模型依赖并运行模型。有关更多使用 Docker 的细节，参考 <a href="https://docs.docker.com/" target="_blank">Docker 官方文档</a>。</li>
            </ol>
        </section>

        <hr>

        <section id="GPT4All">
            <h2>方法3：使用 GPT4All 桌面客户端</h2>
            <p>GPT4All 是一个支持本地运行的开源聊天模型，适合普通电脑用户，不需要编程能力。</p>
            <p><strong>优化步骤：</strong></p>
            <ol>
                <li>访问 GPT4All 官方网站并下载对应操作系统的客户端：</li>
                <ul>
                    <li><a href="https://gpt4all.io/installers/gpt4all-installer-win64.exe" target="_blank">Windows 版本下载</a></li>
                    <li><a href="https://gpt4all.io/installers/gpt4all-installer-linux.run" target="_blank">Linux 版本下载</a></li>
                </ul>
                <li>安装并启动客户端，初次运行时模型会自动下载。</li>
                <li>模型下载完成后即可离线使用。有关 GPT4All 的更新内容和发布说明可以在 <a href="https://forms.nomic.ai/gpt4all-release-notes-signup" target="_blank">这里</a> 注册接收。</li>
            </ol>
        </section>
    </div>

</body>
</html>
